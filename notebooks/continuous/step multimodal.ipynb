{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "complex-data-analysis-4",
   "display_name": "complex-data-analysis-4",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Step Multimodal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.append(\"../../\")\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from captum.attr import (DeepLift, DeepLiftShap, FeatureAblation,\n",
    "                         FeaturePermutation, GradientShap, GuidedBackprop,\n",
    "                         InputXGradient, IntegratedGradients, NoiseTunnel,\n",
    "                         Saliency, ShapleyValueSampling)\n",
    "from evobench.continuous import StepMultimodal\n",
    "from evosolve.continuous import dg2\n",
    "import plotly.io as pio\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from hell import Surrogate, SurrogateData, plot, util\n",
    "from hell.linkage import EmpiricalLinkage\n",
    "\n",
    "seed_everything(42)\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = StepMultimodal(blocks=[10] * 10, step_size=2, verbose=1)\n",
    "\n",
    "x_preprocessing = Pipeline([\n",
    "    (\"standard-scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "y_preprocessing = Pipeline([\n",
    "    (\"min-max-scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "data = SurrogateData(\n",
    "    benchmark,\n",
    "    x_preprocessing, y_preprocessing,\n",
    "    n_samples=1e5, splits=(0.6, 0.2, 0.2),\n",
    "    batch_size=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? sanity check\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=200, nthread=8)\n",
    "xgb_model.fit(data.x_train, data.y_train)\n",
    "y_pred = xgb_model.predict(data.x_test)\n",
    "r2_score(data.y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = Surrogate(\n",
    "    benchmark.genome_size,\n",
    "    x_preprocessing, y_preprocessing,\n",
    "    n_layers=1, learning_rate=2e-4, weight_decay=1e-8\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor=\"val/r2\",\n",
    "   min_delta=0.000,\n",
    "   patience=5,\n",
    "   verbose=False,\n",
    "   mode=\"max\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=100,\n",
    "    gpus=1,\n",
    "    progress_bar_refresh_rate=50,\n",
    "    callbacks=[early_stop_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(surrogate, data.data_module)\n",
    "surrogate.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "xai_results = util.test_xais(\n",
    "    benchmark,\n",
    "    data.x_preprocessing,\n",
    "    decomposers=[\n",
    "        EmpiricalLinkage(benchmark, DeepLift(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, FeatureAblation(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, GradientShap(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, GuidedBackprop(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, InputXGradient(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, IntegratedGradients(surrogate), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, NoiseTunnel(IntegratedGradients(surrogate)), data.x_preprocessing),\n",
    "        EmpiricalLinkage(benchmark, Saliency(surrogate), data.x_preprocessing),\n",
    "    ],\n",
    "    n_samples=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.ffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.ffe = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg2_results = util.test_decomposer(\n",
    "    dg2.EmpiricalLinkage(benchmark), n_samples=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.ffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([xai_results, dg2_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.hit_ratio(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.ranking_metric(\n",
    "    results,\n",
    "    metric=\"mean_reciprocal_rank\",\n",
    "    title=\"Mean Reciprocal Ranking\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.ranking_metric(\n",
    "    results,\n",
    "    metric=\"mean_average_precision\",\n",
    "    title=\"Mean Average Precision\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.ranking_metric(\n",
    "    results,\n",
    "    metric=\"ndcg$1\",\n",
    "    title=\"NDCG$1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean = results.groupby(by=\"method\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean.T.to_csv(\"trap.csv\")"
   ]
  }
 ]
}